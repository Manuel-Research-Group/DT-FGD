Title: DT-FGD – Memory-Efficient Filter-Guided Diffusion with Domain Transform Filtering
Authors: Gustavo Lopes Tamiosso; Caetano Müller; Lucas Spagnolo Bombana; Manuel M. Oliveira (advisor)
Affiliation: Graduate Program in Computer Science (PPGC), Institute of Informatics (INF), Federal University of Rio Grande do Sul (UFRGS), Porto Alegre, RS, Brazil
Tested OS: Ubuntu 22.04 LTS (vanilla install) and Fedora Workstation 42

Overview:
DT-FGD is a lightweight variant of Filter-Guided Diffusion that replaces the cross-bilateral step with an efficient Domain Transform (NC-DT) filter and adds a normalization strategy for the guidance latent. The repo includes a no-parameter script and configs to regenerate a representative figure and comparisons against the original FGD (provided as a git submodule).

-------------------------------------------------------------------------------
How to install and run (no parameters)
-------------------------------------------------------------------------------
Prereqs: a fresh Ubuntu 22.04, Miniconda (or Anaconda), and a CUDA-capable NVIDIA GPU. No manual PATH setup required.

1) Clone and init submodule:
   git clone https://github.com/Manuel-Research-Group/DT-FGD.git
   cd DT-FGD
   git submodule update --init --recursive

2) One-click script (creates the conda env if missing and runs experiments):
   ./setup_run.sh

   Notes:
   - Stable Diffusion model weights are downloaded from Hugging Face on first run
     (CreativeML OpenRAIL-M license must be accepted by the user).

-------------------------------------------------------------------------------
Representative figure (Requirement #2)
-------------------------------------------------------------------------------
To reproduce ONLY the representative figure from the paper (cat in a red hat portrait), run:

   ./replicate_representative.sh

Representative image will be written to `results/red_hat_dtfgd.png`

Representative PNG thumbnail (250x250) is available at:
   docs/representative_250.png
Raw URL for forms:
   https://raw.githubusercontent.com/Manuel-Research-Group/dtFGD/main/docs/representative_250.png

-------------------------------------------------------------------------------
Dependencies and licenses (Requirement #10)
-------------------------------------------------------------------------------
Code: MIT License (see LICENSE).
Submodule (original FGD): MIT (upstream repository).
Libraries: PyTorch (BSD-3-Clause), Diffusers/Transformers/Accelerate/Taichi (Apache-2.0), NumPy (BSD), TQDM (MIT), Pillow (permissive).
Models: Stable Diffusion weights under CreativeML OpenRAIL-M (accepted during download).

-------------------------------------------------------------------------------
Hardware and runtime notes
-------------------------------------------------------------------------------
GPU recommended (≥12 GB VRAM).
Typical runtime on consumer GPU: a few minutes per image.

-------------------------------------------------------------------------------
Determinism and Cross-GPU Reproducibility
-------------------------------------------------------------------------------
Runs with fixed seeds on the same GPU model and software stack are reproducible.
Across different GPUs or CUDA/cuDNN/driver versions, results can differ,
especially at higher resolutions (e.g., 1024×1024), due to architecture-specific
kernel selection and floating-point rounding differences in attention/conv ops.
This behavior is expected for diffusion models.

In our tests, 1024×1024 images showed more pronounced differences across GPUs
other than the RTX 3090 (our main test platform). The `red_hat` example was
selected as representative because it produces visually similar outputs across
tested GPUs.

-------------------------------------------------------------------------------
File layout (key files)
-------------------------------------------------------------------------------
run_experiment.py            # main entry point
replicate_representative.sh                 # no-parameter end-to-end script for representative image
setup_run.sh                 # no-parameter end-to-end script
configs/*.json               # configs for paper figures
src/diffusionModel.py        # modified diffusion pipeline (supports --decode-cpu, plotting)
src/dtFGD.py, src/ncdt.py    # DT-FGD implementation
FilteredGuidedDiffusion/     # original FGD (git submodule)
results/                     # outputs (auto-created)
docs/representative_250.png  # 250×250 thumbnail

-------------------------------------------------------------------------------
Contact
-------------------------------------------------------------------------------
Gustavo Tamiosso <gltamiosso@inf.ufrgs.br>
Affiliation: PPGC/INF/UFRGS, Porto Alegre, RS, Brazil
